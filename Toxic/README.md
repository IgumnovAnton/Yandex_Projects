# Токсичные комментарии

Ссылки на nbviewer, если GitHub не прогружает тетрадку

[Toxic_BERT](https://nbviewer.org/github/IgumnovAnton/Yandex_Projects/blob/main/Toxic/Toxic_BERT.ipynb)

[Toxic_TFIDF](https://nbviewer.org/github/IgumnovAnton/Yandex_Projects/blob/main/Toxic/Toxic_TFIDF.ipynb)


Проект выполнен в двух вариантах для образовательных целей:
- Toxic_BERT.ipynb с использованием предобученной модели BERT
- Toxic_TFIDF.ipynb с использованием tf-idf

## **Info**
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. 

То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

**Цель:**
- создать модель прогнозирования количества заказов такси на следующий час

**Метрика:**
- метрика для оценки качества модели **f1**

**Точность:**
- f1 лучшей модели должен быть не меньше **0.75**


## **Data**

Данные были предоставленны Яндексом для образовательных целей. 
Таблица представляет из себя набор размеченных токсичных комментариев.

Таблица `toxic_comments.csv` - 159451 строк и 2 колонки
Столбец `text` содержит текст комментария, а `toxic` — целевой признак.

## **Analysis** 

При осмотре данных были обнаружены пропуски в таргете - 131 пропущенное значение (были выброшены из даитасета)

Так же, в таргете были обнаружены комментарии, что, скорее всего, стало ошибкой при выгрузке датасета - так же были удалены.

Наблюдается явный дисбаланс разметки таргета:
- 143106 НЕ токсичных комментариев с флагом 0
- 16186 токсичных комментариев с флагом 1

## **Features** 

**TF-IDF**

Для метода tf-idf комментарии прошли очистку от мусора:
- удалены значи препинания и другие не нужные символы

К датасету была добавлена колонка с лемматизированными комментариями.

К колонке с лемматизированными комментраями был применен метод tf-idf

**BERT**

Для метода BERT комментарии, так же, прошли очистку от мусора:
- удалены значи препинания и другие не нужные символы

Из-за отсутствия ресурсов было выбрано 1000 рандомных семплов, для дальнейшей работы

Токенезировали фичи с помощью distilbert-base-uncased и создали эмбединги.


## **Modeling and Testing**

**TF-IDF**

Для работы с использованием tf-idf было использованно 3 модели:
- Logistic Regression (balanced)
- tuned Logistic Regression
- LightGBM (из-за скорости и точности)

| LogReg | tuned LogReg | LightGBM |
|:---:|:---:|:---:|
| 0.75 | 0.76 | 0.78 | 

**BERT**

Для работы с BERT было использованно большее количество моделей и способов борьбы с дисбалансом:
- Logistic Regression
- Logistic Regression + RandomOverSample
- Logistic Regression + SMOTE
- Logistic Regression + ADASYN
Тк метод SMOTE показал лучшие результаты:
- Random Forest + SMOTE
- CatBoost + SMOTE
- LightGBM + SMOTE

| LogReg | Random Forest | CatBoost | tuned LogReg | LightGBM |
|:---:|:---:|:---:|:---:|:---:|
| 0.70 | 0.68 | 0.67 | 0.64 | 0.64 |


## **Conclusion**

Модель с необходимой точностью создана.

**Лучший результат показала LightGBM: 0.78**

Метод TF-IDF оказался точнее в данном случае.

Метод с BERT оказался не совсем подходящей для данной задачи:
- требует в разы больше мощности для вычисления
- затраты времени на настройку и проверку вариантов значительно выше



